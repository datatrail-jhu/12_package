expect_is(g$theme$panel.grid.major, "element_blank")
g$theme$panel.background
g$theme$panel.background$fill
expect_equal(g$theme$panel.background$fill, "white")
g$theme$axis.line.y
g$theme$axis.line
?theme_classic
theme_classic
g$theme$axis.line
g$theme$axis.line$colour
test_that("plot theme defaults", {
expect_equal(as.character(g$theme$axis.ticks.length), "0cm")
expect_is(g$theme$panel.grid.major, "element_blank")
expect_equal(g$theme$panel.background$fill, "white")
expect_equal(g$theme$axis.line$colour, "black")
})
p <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point()
test_that("plot theme defaults", {
expect_equal(as.character(p$theme$axis.ticks.length), "0cm")
expect_is(p$theme$panel.grid.major, "element_blank")
expect_equal(p$theme$panel.background$fill, "white")
expect_equal(p$theme$axis.line$colour, "black")
})
test_that("plot theme defaults", {
#expect_equal(as.character(p$theme$axis.ticks.length), "0cm")
expect_is(p$theme$panel.grid.major, "element_blank")
expect_equal(p$theme$panel.background$fill, "white")
expect_equal(p$theme$axis.line$colour, "black")
})
#expect_equal(as.character(p$theme$axis.ticks.length), "0cm")
#expect_is(p$theme$panel.grid.major, "element_blank")
expect_equal(p$theme$panel.background$fill, "white")
#expect_equal(as.character(p$theme$axis.ticks.length), "0cm")
#expect_is(p$theme$panel.grid.major, "element_blank")
#expect_equal(p$theme$panel.background$fill, "white")
expect_equal(p$theme$axis.line$colour, "black")
#expect_equal(as.character(p$theme$axis.ticks.length), "0cm")
expect_is(p$theme$panel.grid.major, "element_blank")
#expect_equal(as.character(p$theme$axis.ticks.length), "0cm")
#expect_is(p$theme$panel.grid.major, "element_blank")
expect_equal(p$theme$panel.background$fill, "white")
g$theme
g$theme$text
g$theme$text$family
expect_equal(p2$theme$text$size, 18)
p2 <- ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point() +
theme_cbds(base_size = 18, base_family = "serif")
test_that("plot theme defaults", {
expect_equal(p2$theme$text$family, "serif")
expect_equal(p2$theme$text$size, 18)
})
p2$theme$text$size
?testthat:use_test
?testthat::use_test
my_value <- 6
expect_equal(my_value, 6)
expect_match(my_value, 6)
expect_identical(my_value, 6)
expect_message(my_value, 6)
expect_is(my_value, 6)
`expect_match(my_string, "learning")`
my_string <- 'learning is the best'
expect_match(my_string, "learning")
expect_match(my_string, learning)
expect_match(my_string, "learning is the best!")
expect_match(my_string, "Best")
?ggplot2
library(ggplot2)
?ggplot2
library(forcats)
?forcats
library(forcats)
?forcats
library(ggplot2)
?ggplot2
?ggplot2
**Suggests**
### Summary
library(dplyr)
?dplyr
?ggplot
?ggplot
?summarise
?@export
emphasize_text <- function(text, emphasis = "!!!"){
out = toupper(text)
out = paste0(out, emphasis)
print(out)
}
browseVignettes("googlesheets")
browseVignettes("ggplot2")
browseVignettes("dplyr")
browseVignettes("forcats")
browseVignettes("datetime")
browseVignettes("lubridate")
browseVignettes("stringr")
?use_vignette
?usethis::use_vignette
library(ggplot2)
library(skimr)
skim(diamonds)
skim(msleep)
trees
?devtools::use_data
?use_data_raw
?usethis::use_data_raw
g5f5d9320fd_0_26
?use_data
?usethis::use_data
?usethis::use_raw_data
?usethis::use_data_raw
?devtools::use_travis
?usethis::use_travis
?create_package
?usethis::create_package
devtools::install_github("janeeverydaydoe/cbds")
library(cbds)
?devtools::use_travis
?usethis::use_travis
library(didactr)
## Define which course to check and build
course_dir="/Users/shannonellis/Desktop/jhudsl_CDS/cds_package"
# Course = "Google and The Cloud"
# Course = "Organizing Data Science Projects"
# Course = "Version Control
# Course = "Introduction to R"
# Course = "Data Tidying"
# Course = "Data Visualization"
# Course = "Getting Data"
# Course = "Data Analysis"
# Course = "Written and Oral Communication in Data Science"
# Course = "Getting a Job in Data Science"
Course = "How To Build An R Package"
## load libraries
library(didactr)
## get current status of course
out <- check_course(course_dir)
## get current status of course
out <- check_course(course_dir)
didactr_auth()
## get current status of course
out <- check_course(course_dir)
didactr::gs_slide_df("1VbKkYRdyWbtc37T7P4IhF1Dd-2SrMKSQmtyG56fVOQ8")$png_markdown
save_metrics = TRUE
timezone = "America/New_York"
require_authorization = TRUE
use_book = FALSE
check_youtube_links = TRUE
lesson_name = gs_name = drive_resource = NULL
rm(list = c("lesson_name", "gs_name", "drive_resource"))
scr_para_length = yt_md_link = vid_file = NULL
rm(list = c("scr_para_length", "yt_md_link", "vid_file"))
mod_time_vid = mod_time_scr = lesson = NULL
rm(list = c("mod_time_vid", "mod_time_scr", "lesson"))
n_slides = pdf_pages = n_pngs = img_dir = lesson = NULL
rm(list = c("img_dir", "lesson", "pdf_pages", "n_pngs", "n_slides"))
mod_time_pngs = gs_more_recent = NULL
rm(list = c("mod_time_pngs", "gs_more_recent"))
mod_time_gs = scr_file = has_scr_file = NULL
rm(list = c("scr_file", "has_scr_file", "mod_time_gs"))
paths = check_structure(course_dir)
paths
######################################
# get manuscript md files and check names of
######################################
manuscript_files = list.files(
pattern = ".md$",
path = paths$man_path,
full.names = TRUE)
use_book
man_stubs = sub("[.]md$", "", basename(manuscript_files))
# md file has highest precedence
df = data_frame(lesson = man_stubs, md_file = manuscript_files)
library(dplyr)
library(tidyr)
library(httr)
library(stringr)
library(lubridate)
library(googledrive)
# md file has highest precedence
df = data_frame(lesson = man_stubs, md_file = manuscript_files)
df
# create a title lesson name
df = df %>%
mutate(lesson_name = stringr::str_replace(lesson, "^\\d+_", ""),
lesson_name = stringr::str_replace_all(lesson_name, "_", " "),
lesson_name = stringr::str_to_title(lesson_name))
## get IDs for Slides
df$id = sapply(df$md_file, gs_id_from_slide)
if (any(is.na(df$id))) {
message(
paste0("Google Slides ID is missing from following lessons: ",
paste0(df$lesson[is.na(df$id)], collapse = ", ")))
}
is_didactr_authorized
is_didactr_authorized()
######################################
## Get information from Google Drive
######################################
d <- df %>%
filter(!is.na(id))
if (nrow(d) > 0 && authorized) {
drive_info = drive_information(id = d$id, timezone = timezone)
if (!is.null(drive_info)) {
drive_info$n_slides = sapply(drive_info$id, function(id) {
nrow(gs_slide_df(id))
})
df = left_join(df, drive_info, by = "id")
df = distinct(df)
}
} else {
df$gs_name = NA
df$mod_time_gs = NA
df$n_slides = NA
}
authorized = is_didactr_authorized()
if (nrow(d) > 0 && authorized) {
drive_info = drive_information(id = d$id, timezone = timezone)
if (!is.null(drive_info)) {
drive_info$n_slides = sapply(drive_info$id, function(id) {
nrow(gs_slide_df(id))
})
df = left_join(df, drive_info, by = "id")
df = distinct(df)
}
} else {
df$gs_name = NA
df$mod_time_gs = NA
df$n_slides = NA
}
library(didactr)
?drive_information
# get script path and number of paragraphs
paragraph_from_script <- function(x) {
if (file.exists(x)) {
para = readLines(x, warn = FALSE)
para = trimws(para)
para = para[!para %in% c("", " ")]
return(para)
} else{
return(NA)
}
}
n_para = function(x) {
x = paragraph_from_script(x)
if (length(x) == 0) {
return(0)
}
ifelse(all(is.na(x)), NA, length(x))
}
length0 = function(x) {
length(x) == 0
}
length0_to_NA = function(x) {
if (length0(x)) {
x <- NA
}
x
}
drive_information = function(id,
timezone = "America/New_York",
...) {
name = gs_name = NULL
rm(list = c("name", "gs_name"))
authorized = check_didactr_auth(...)
drive_info = googledrive::drive_get(id = id)
if (nrow(drive_info) > 0) {
drive_info = drive_info %>%
rename(gs_name = name) %>%
mutate(course_info = gs_name)
mod_time_gs = sapply(drive_info$drive_resource,
function(x) {
x$modifiedTime
})
drive_info$mod_time_gs = lubridate::ymd_hms(
mod_time_gs)
drive_info$mod_time_gs = lubridate::with_tz(
drive_info$mod_time_gs,
tzone = timezone)
drive_info$drive_resource = NULL
} else {
return(NULL)
}
return(drive_info)
}
drive_find_folder = function(
pattern = "^cds",
..., shared_with_me = FALSE) {
args = list(...)
args$pattern = pattern
if (shared_with_me) {
if ("q" %in% names(args)) {
warning("q is overridden when finding")
}
args$q = "sharedWithMe"
}
args$type = "folder"
do.call(googledrive::drive_find, args = args)
}
#' Google Slides Helper Functions
#'
#' @param file markdown file for manuscript
#'
#' @return A scalar character vector
#' @export
#' @rdname gs_helpers
gs_id_from_slide = function(file) {
if (!file.exists(file)) {
return(NA_character_)
}
x = readLines(file, warn = FALSE)
ind = grep(x, pattern = "\\[(S|s)lides\\]")
if (length(ind) > 0) {
x = x[ind]
} else {
x = x[grep(x, pattern = ".*presentation/d/")]
}
if (!any(grepl("http", x))) {
return(NA_character_)
}
x = sub(".*\\(\\s*(http.*)\\s*\\).*", "\\1", x)
x = unlist(sapply(x, function(r) httr::parse_url(r)$path))
x = sub("/edit$", "", x)
x = sub("/export/.*", "", x)
x = basename(x)
x = stats::na.omit(x)
x = x[ nchar(x) > 5 ]
ux = unique(x)
if (length(ux) > 1) {
warning(paste0("Multiple sheets identified! Taking most frequent.",
"  Please check ",
file))
x = sort(table(x), decreasing = TRUE)
x = names(x)[1]
# x = x[1]
} else {
x = ux
}
if (length(x) == 0 || grepl("\\(\\)", x)) {
return(NA_character_)
}
if (nchar(x) < 10) {
warning(paste0("ID extracted is ", x, ", seems short"))
}
return(x)
}
######################################
# this returns the actual links in the text
######################################
#' @export
#' @rdname gs_helpers
get_image_link_from_slide = function(file) {
x = readLines(file, warn = FALSE)
x = grep(x, pattern = "!\\[.*\\]\\(((resources/|)images.*)\\)", value = TRUE)
x = sub(x, pattern = "!\\[(.*)\\]\\(((resources/|)images.*)\\)", replacement = "\\1")
# if (length(x) == 0) {
#   return(NA)
# }
return(x)
}
######################################
# this returns the actual image filenames referenced
# we will check to see if all images referenced exist
######################################
#' @export
#' @rdname gs_helpers
get_image_from_slide = function(file) {
x = readLines(file, warn = FALSE)
x = grep(x, pattern = "!\\[.*\\]\\(((resources/|)images.*)\\)", value = TRUE)
x = sub(x, pattern = "!\\[.*\\]\\(((resources/|)images.*)\\)", replacement = "\\1")
# if (length(x) == 0) {
#   return(NA)
# }
return(x)
}
list_one_file = function(x, ending = "pdf") {
pdfs = list.files(
pattern = paste0("[.]", ending),
path = x,
full.names = TRUE)
if (length(pdfs) > 1) {
warning(paste0(x, " had more than one ", ending, "! ",
"Only grabbing first"))
pdfs = pdfs[1]
}
pdfs = length0_to_NA(pdfs)
return(pdfs)
}
mod_time_to_tz_time = function(x, timezone) {
mod_times = file.info(x)$mtime
mod_times = lubridate::ymd_hms(mod_times, tz = Sys.timezone())
mod_times = lubridate::with_tz(mod_times, tzone = timezone)
return(mod_times)
}
png_pattern = function() {
paste0("^!\\[.+\\]\\((?!\\.png)\\)|",
"^!\\[\\]\\((?!\\.png)\\)|",
"^!\\[.+\\]\\((?!\\.png)\\)|",
"!\\[.+\\]\\(.+[^.png]\\)|",
"^!\\[.+\\]\\(https\\:\\/\\/www\\.youtu.+\\)")
}
yt_pattern = function() {
paste0("^!\\[.+\\]\\(https\\:\\/\\/www\\.youtu.+\\)|",
"^!\\[.+\\]\\(https\\:\\/\\/youtu.+\\)")
}
is.Token = function(token) {
inherits(token, "Token")
}
na_false = function(test) {
test[ is.na(test)] = FALSE
test
}
na_true = function(test) {
test[ is.na(test)] = TRUE
test
}
add_gh_collaborator = function(owner, repo,
collaborator = "leanpub",
auth_token) {
lapply(collaborator, function(collab) {
gh::gh(paste0(
"PUT /repos/", owner, "/",
repo, "/collaborators/",
collab), .token = auth_token)
})
res = gh::gh(paste0(
"GET /repos/", owner, "/",
repo, "/collaborators"), .token = auth_token)
collabs = sapply(res, function(x) {
x$login
})
result = collaborator %in% collabs
names(result) = collaborator
if (!all(result)) {
warning("Not all collaborators have been added!")
}
result
}
os_type <- function() {
.Platform$OS.type
}
sys_type <- function() {
if (os_type() == "windows") {
"windows"
} else if (Sys.info()["sysname"] == "Darwin") {
"macos"
} else if (Sys.info()["sysname"] == "Linux") {
"linux"
} else if (os_type() == "unix") {
# "unix"
"linux"
} else {
stop("Unknown OS")
}
}
png_url = function(id, page_id) {
paste0(
"https://docs.google.com/presentation/d/",
id, "/export/png?id=", id,
"&pageid=", page_id)
}
download_png_urls = function(urls) {
res = vapply(urls, function(url) {
tfile = tempfile(fileext = ".png")
httr::GET(url, httr::write_disk(tfile))
tfile
}, FUN.VALUE = character(1))
return(res)
}
if (nrow(d) > 0 && authorized) {
drive_info = drive_information(id = d$id, timezone = timezone)
if (!is.null(drive_info)) {
drive_info$n_slides = sapply(drive_info$id, function(id) {
nrow(gs_slide_df(id))
})
df = left_join(df, drive_info, by = "id")
df = distinct(df)
}
} else {
df$gs_name = NA
df$mod_time_gs = NA
df$n_slides = NA
}
drive_info = drive_information(id = d$id, timezone = timezone)
View(d)
View(d$id)
d$id
## get current status of course
out <- check_course(course_dir)
View(out$course_summary)
## Create Videos
## tell R what AWS keys to use
aws.signature::use_credentials(profile="polly")
out <- create_videos(out, subtitles=TRUE)
## get current status of course
out <- check_course(course_dir)
View(out$course_summary)
## get current status of course
out <- check_course(course_dir)
out <- create_videos(out, subtitles=TRUE)
Sys.timezone()
## get current status of course
out <- check_course(course_dir, timeone = "America/Los_Angeles")
out <- create_videos(out, subtitles=TRUE, timezone = America/Los_Angeles)
?create_videos
?check_course
out <- create_videos(out, subtitles=TRUE)
## get current status of course
out <- check_course(course_dir, timeone = "America/Los_Angeles")
out <- create_videos(out, subtitles=TRUE)
